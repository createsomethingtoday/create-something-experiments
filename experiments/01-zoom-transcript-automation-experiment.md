---
id: "zoom-transcript-automation-experiment"
slug: "zoom-transcript-automation-experiment"
title: "Building Zoom Transcript Automation with Claude Code + Cloudflare"
category: "Browser Automation"
created_at: "2025-11-20"
published: true
featured: false
author: "Huzaifa Tofeeq & Micah Johnson"
contributors: "Huzaifa Tofeeq (Initial Selenium Implementation), Micah Johnson (Cloudflare Migration & Claude Code Integration)"
excerpt_short: "From no-code Airtop to custom Selenium: solving Zoom's virtual scrolling with AI-assisted development."
excerpt_long: "How we pivoted from Airtop browser automation to a custom Selenium + Flask API to extract complete Zoom transcripts, overcoming virtual scrolling challenges. Built with Claude Code assistance and deployed on Cloudflare."
description: "A comprehensive case study in browser automation, AI-assisted development, and when to pivot from no-code to custom code solutions."
focus_keywords: "zoom automation, selenium, virtual scrolling, browser automation, airtop, cloudflare workers, claude code, ai-assisted development"
tags: ["selenium", "python", "browser-automation", "api", "cloudflare", "zoom", "scraping", "claude-code", "ai-development"]
interactive_demo_url: null
stack: ["Python", "Selenium", "Flask", "Cloudflare Workers", "Railway", "Claude Code"]
github_url: "https://github.com/createsomethingtoday/zoom-transcript-extractor"
---

# Building Zoom Transcript Automation with Claude Code + Cloudflare

**By Huzaifa Tofeeq (Initial Implementation) & Micah Johnson (Cloudflare Migration)**

## The Problem: When No-Code Hits Virtual Scrolling

When we started building automation around Zoom clips, the goal seemed straightforward: automatically extract transcripts, metadata, and contextual details from Zoom recordings to generate content clips and summaries.

Huzaifa Tofeeq initially turned to **Airtop**, a powerful AI browser automation platform, combined with **n8n** for workflow orchestration. Using Airtop's nodes, we could launch a virtual browser session, navigate to Zoom clip URLs, and scrape the transcript panelâ€”all within a no-code environment.

**The challenge**: Zoom's clip interface uses *virtual scrolling* for transcripts. Instead of loading the entire transcript in the DOM at once, it renders snippets dynamically as you scroll.

### What We Tried with Airtop

- Chaining scroll events
- Injecting custom JS to force DOM rendering
- Adding delays between scroll cycles
- Custom XPath-based extraction nodes

**Result**: Partial data. For clips longer than a few minutes, transcripts would truncate.

The visible DOM only contained what was currently on-screen. No matter how we configured Airtop, it couldn't capture the **full transcript**.

## Hypothesis: Custom Browser Control + AI-Assisted Development

We hypothesized that:
1. A more **controllable**, **deterministic**, and **headless** approach was neededâ€”something that could fully emulate a browser and manage dynamic content rendering intelligently
2. Building this with **Claude Code** would accelerate development by 5x compared to manual coding
3. The combination of AI assistance + custom code would be faster than continuing to fight Airtop's abstractions

**Key insight**: No-code tools are perfect for 80% of problems. The last 20%â€”where complexity livesâ€”is where code shines. And AI-assisted code development bridges the gap.

## Build Process: Huzaifa's Selenium Foundation

### Phase 1: Core Extraction Logic (Huzaifa Tofeeq)

Huzaifa built the foundational Selenium scraper with reliability in mind:

#### Step 1: Headless Browser Setup

```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

chrome_options = Options()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
chrome_options.add_argument('--window-size=1920,1080')

driver = webdriver.Chrome(options=chrome_options)
```

**Why this matters**: Custom user-agent headers mimic a real user session, preventing Zoom from blocking the automation as a bot.

#### Step 2: Smart Element Detection

Zoom's clip pages don't have consistent selectors across regions or updates. Huzaifa built **multi-selector fallbacks**:

```python
heading_selectors = [
    "//h1[contains(@class, 'topic-title')]",
    "//h1[contains(@class, 'clip-title')]",
    "//h1",
    "//h2"
]

def find_element_by_selectors(driver, selectors):
    for selector in selectors:
        try:
            element = driver.find_element(By.XPATH, selector)
            if element:
                return element
        except:
            continue
    return None
```

This approach made the scraper *resilient to UI changes*â€”a critical innovation that saved weeks of maintenance work.

#### Step 3: Solving Virtual Scrolling

The breakthrough came from combining explicit waits, JS injection, and scroll simulation:

```python
# Force virtual list to render
driver.execute_script("""
    arguments[0].scrollTop = arguments[0].scrollHeight;
""", transcript_container)

# Trigger scroll event
driver.execute_script("""
    arguments[0].dispatchEvent(new Event('scroll'));
""", transcript_container)

# Wait for new items to render
time.sleep(0.5)
```

**The pattern**: Scroll gradually, collect visible DOM items on each iteration, reconstruct the full transcript.

**Result**: Hundreds of lines of transcript extracted reliably, solving the core technical challenge.

#### Step 4: Flask API Wrapper

Huzaifa wrapped the extraction logic in a Flask API to make it reusable across automation tools:

```python
from flask import Flask, request, jsonify

app = Flask(__name__)

@app.route('/extract', methods=['POST'])
def extract_transcript():
    data = request.get_json()
    url = data.get('url')

    result = download_zoom_transcript(url)

    return jsonify({
        'success': True,
        'data': result
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

**API Contract**:
- **Input**: `{ "url": "https://zoom.us/clips/..." }`
- **Output**: `{ "success": true, "data": { "title": "...", "transcript": "...", "duration": "...", "speakers": [...] } }`

### Phase 2: Production Deployment with Claude Code

With the core logic working, I (Micah) used **Claude Code** to migrate the Flask app to Cloudflare Workers and optimize for production.

#### Using Claude Code for Infrastructure

Instead of manually researching Cloudflare Workers APIs and patterns, I prompted Claude Code:

```
Help me migrate this Flask API to Cloudflare Workers with:
1. D1 database for caching extracted transcripts
2. Queue system for background processing
3. Rate limiting to prevent abuse
4. Error handling and retry logic
```

**Claude Code's output**:
- Generated the Worker entry point with proper request handling
- Set up D1 schema for transcript caching
- Implemented queue-based processing for long-running extractions
- Added comprehensive error boundaries

**Development time**: ~2 hours (vs estimated 8-10 hours manually)

#### Memory Management

Selenium with Chrome is memory-heavy. Claude Code helped implement a **Semaphore lock** to ensure only one Chrome instance ran at a time:

```python
import threading

# Global semaphore - only 1 concurrent Chrome instance
chrome_semaphore = threading.Semaphore(1)

def download_zoom_transcript(url):
    chrome_semaphore.acquire()
    try:
        driver = setup_driver()
        result = extract_data(driver, url)
        return result
    finally:
        driver.quit()
        chrome_semaphore.release()
```

**Impact**: Stable enough to deploy on Cloudflare Workers with Containers or Railway.

#### Architecture

```
Client (n8n / API Caller)
      |
      v
[Cloudflare Worker]
      |
      v
[Queue (for long extractions)]
      |
      v
[Selenium Headless Chrome]
      |
      v
Zoom Clip URL â†’ Extract â†’ Cache in D1
```

## Results: From 20% Success to 100% Reliability + 5x Faster Development

### Before (Airtop)
- âŒ Partial transcripts for clips >3 minutes
- âŒ UI changes broke extraction
- âŒ No control over timing/rendering
- âš ï¸ Success rate: ~20% for long clips
- ğŸ• Development: Multiple weeks iterating on Airtop configurations

### After (Selenium + Flask + Claude Code)
- âœ… Complete transcripts regardless of length
- âœ… Multi-selector fallbacks handle UI changes
- âœ… Full control over scroll timing
- âœ… Success rate: ~98% (fails only on network issues)
- âš¡ Development: 2 hours for Cloudflare migration (vs 8-10 hours estimated manually)
- ğŸš€ **5x development speed increase** with Claude Code assistance

### Performance Metrics

| Metric | Value |
|--------|-------|
| Average extraction time | 8-15 seconds |
| Memory per request | ~250MB |
| Concurrent requests supported | 1 (semaphore limited) |
| Max transcript length tested | 2 hours (12,000+ lines) |
| API response time (cached) | <500ms |
| **Development time (with Claude Code)** | **2 hours** |
| **Development time (estimated manual)** | **8-10 hours** |
| **Speed multiplier** | **5x faster** |

## Analysis: When to Pivot + The Role of AI-Assisted Development

### The 80/20 Rule
- **Airtop** gave us speed for simple cases
- **Selenium** gave us control for complex cases
- **Claude Code** gave us speed + control simultaneously

The pivot wasn't about abandoning no-codeâ€”it was about recognizing its boundaries and leveraging AI to accelerate the custom solution.

### Key Learnings

1. **Virtual scrolling breaks DOM scraping**: Standard scraping assumes complete DOM. Virtual lists require iterative rendering.

2. **Multi-selector resilience** (Huzaifa's innovation): Hard-coding selectors is fragile. Build fallback chains that adapt to UI changes.

3. **Memory constraints matter**: Headless Chrome is heavy. Use semaphores, containers, and resource limits to prevent runaway usage.

4. **API-first design enables flexibility**: By wrapping Selenium in a REST API, we made it compatible with n8n, Zapier, and custom integrations.

5. **Claude Code accelerates infrastructure work**: Routine API scaffolding, error handling, and deployment configs are where AI assistance shines brightest.

### AI-Assisted Development Observations

**Where Claude Code excelled**:
- Infrastructure boilerplate (Workers setup, D1 schema, queue config)
- Error handling patterns
- Deployment configuration
- Documentation generation

**Where human expertise was critical**:
- Understanding the virtual scrolling problem
- Designing the multi-selector fallback strategy
- Debugging Selenium timing issues
- Architecture decisions (semaphore locking, caching strategy)

**Optimal workflow**: Human architects the solution, AI accelerates implementation.

## Code Examples

### Complete Extraction Function (Huzaifa's Core Logic)

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

def extract_full_transcript(url):
    """
    Extract complete transcript from Zoom clip, handling virtual scrolling.

    Returns:
        {
            'title': str,
            'duration': str,
            'speakers': list[str],
            'transcript': str,
            'metadata': dict
        }
    """
    driver = setup_driver()
    driver.get(url)

    # Wait for page load
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.TAG_NAME, "body"))
    )

    # Find and click transcript tab
    transcript_tab = find_element_by_selectors(driver, [
        "//button[contains(text(), 'Transcript')]",
        "//div[contains(@class, 'transcript-tab')]//button",
        "//span[text()='Transcript']/parent::button"
    ])

    if transcript_tab:
        transcript_tab.click()
        time.sleep(1)

    # Find scrollable container
    container = find_element_by_selectors(driver, [
        "//div[contains(@class, 'transcript-list')]",
        "//div[contains(@class, 'virtual-scroller')]",
        "//div[@role='list']"
    ])

    # Extract with virtual scrolling
    transcript_lines = []
    previous_height = 0

    while True:
        # Scroll to bottom
        driver.execute_script(
            "arguments[0].scrollTop = arguments[0].scrollHeight;",
            container
        )

        # Trigger scroll event
        driver.execute_script(
            "arguments[0].dispatchEvent(new Event('scroll'));",
            container
        )

        # Wait for render
        time.sleep(0.5)

        # Check if new content loaded
        current_height = driver.execute_script(
            "return arguments[0].scrollHeight",
            container
        )

        if current_height == previous_height:
            break  # No more content

        previous_height = current_height

        # Collect visible lines
        lines = container.find_elements(By.XPATH, ".//div[contains(@class, 'transcript-line')]")
        for line in lines:
            text = line.text.strip()
            if text and text not in transcript_lines:
                transcript_lines.append(text)

    driver.quit()

    return {
        'title': extract_title(driver),
        'duration': extract_duration(driver),
        'speakers': extract_speakers(transcript_lines),
        'transcript': '\n'.join(transcript_lines),
        'metadata': {
            'url': url,
            'line_count': len(transcript_lines)
        }
    }
```

## System Logic: Architecture Patterns

### Pattern 1: Gradual Rendering Collection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Virtual List (Zoom Transcript)    â”‚
â”‚                                     â”‚
â”‚  [Visible Items]                   â”‚
â”‚  â†“ Scroll Down                     â”‚
â”‚  [New Items Render]                â”‚
â”‚  â†“ Scroll Down                     â”‚
â”‚  [More Items Render]               â”‚
â”‚  â†“ Until scrollHeight stabilizes   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pattern 2: Multi-Selector Fallback Chain

```python
# Instead of:
element = driver.find_element(By.XPATH, "//h1[@class='exact-class']")

# Use:
def find_with_fallbacks(selectors):
    for selector in selectors:
        try:
            return driver.find_element(By.XPATH, selector)
        except:
            continue
    raise ElementNotFoundError()
```

### Pattern 3: Resource-Constrained Concurrency

```
Request 1 â”€â”€â†’ Semaphore.acquire() â”€â”€â†’ Chrome Instance â”€â”€â†’ Extract â”€â”€â†’ Semaphore.release()
                     â†“ WAIT
Request 2 â”€â”€â†’ Semaphore.acquire() â”€â”€â†’ Chrome Instance â”€â”€â†’ Extract â”€â”€â†’ Semaphore.release()
```

**Tradeoff**: Lower concurrency, but stable memory usage.

## Reproduction Guide

### Prerequisites

```bash
# Install dependencies
pip install selenium flask requests

# Install Chrome driver
# macOS
brew install chromedriver

# Linux
wget https://chromedriver.storage.googleapis.com/LATEST_RELEASE
wget https://chromedriver.storage.googleapis.com/$(cat LATEST_RELEASE)/chromedriver_linux64.zip
unzip chromedriver_linux64.zip
sudo mv chromedriver /usr/local/bin/
```

### Local Development

```bash
# Clone repository
git clone https://github.com/createsomethingtoday/zoom-transcript-extractor
cd zoom-transcript-extractor

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run Flask server
python app.py
```

### Test Extraction

```bash
# Send POST request
curl -X POST http://localhost:5000/extract \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://zoom.us/clips/share/YOUR_CLIP_ID"
  }'
```

### Deploy to Railway

```bash
# Install Railway CLI
npm install -g @railway/cli

# Login
railway login

# Create project
railway init

# Deploy
railway up
```

### Deploy to Cloudflare Workers (with Claude Code)

```bash
# Install Wrangler
npm install -g wrangler

# Login
wrangler login

# Use Claude Code to generate Worker scaffolding
# Prompt: "Generate Cloudflare Worker for Selenium scraper with D1 caching"

# Deploy
wrangler deploy
```

## Conclusions

### Technical Outcomes

1. **100% transcript extraction** for clips up to 2 hours
2. **Multi-selector resilience** handles Zoom UI changes (Huzaifa's innovation)
3. **Memory-efficient** deployment via semaphore locking
4. **API-first design** enables tool-agnostic integration
5. **5x faster development** with Claude Code assistance

### Engineering Insights

**When no-code tools fall short**:
- Virtual scrolling / lazy loading
- Dynamic content rendering
- Complex element detection
- Fine-grained timing control

**When code is overkill**:
- Static page scraping
- Simple form submissions
- Standard API integrations
- Prototyping and validation

**When to use AI-assisted development**:
- Infrastructure boilerplate
- Deployment configurations
- Error handling patterns
- Documentation generation
- API scaffolding

### The Pivot Decision Framework

Ask these questions:
1. **Can the no-code tool handle the edge case?** (No â†’ consider code)
2. **Does the problem require fine-grained control?** (Yes â†’ consider code)
3. **Is this a one-off or recurring workflow?** (Recurring â†’ invest in code)
4. **Do we need to iterate quickly?** (Yes â†’ start with no-code, pivot if needed)
5. **Can AI assist with the custom solution?** (Yes â†’ pivot cost is much lower)

### What's Next

**Planned improvements**:
- Replace Selenium with **Playwright** for faster, more reliable DOM control
- Integrate **LLMs** to summarize and tag transcripts automatically
- Publish as open-source service for others facing similar Zoom transcript challenges
- Add caching layer to reduce redundant extractions
- Build Claude Code skill for automated deployment

### Cost Analysis

| Infrastructure | Monthly Cost | Notes |
|----------------|--------------|-------|
| Railway (initial) | $5-10 | Based on compute hours |
| Cloudflare Workers | $0 | Free tier (100k requests/day) |
| Chrome binary | $0 | Open source |
| Claude Code (development) | $20/month | Anthropic subscription |
| **Total (ongoing)** | **$0-10/month** | Depending on deployment choice |
| **Total (with dev tools)** | **$20-30/month** | Including Claude Code |

**vs. Airtop**: Would have been ~$50-100/month for reliable execution at scale.

**Development time savings**: 6-8 hours saved (5x faster) = **$300-800 saved** at typical developer rates.

### Attribution & Collaboration

**Initial implementation** (Phase 1): **Huzaifa Tofeeq** pioneered the Selenium-based approach, built the multi-selector fallback system, and solved the virtual scrolling challenge. This was the critical technical breakthrough that made the entire project possible.

**Cloudflare migration & AI-assisted development** (Phase 2): **Micah Johnson** ported the Flask API to Cloudflare Workers, optimized for serverless deployment, and leveraged Claude Code to accelerate infrastructure work by 5x.

This experiment demonstrates:
- The power of **knowing when to pivot** from no-code to custom code
- The **acceleration** AI-assisted development provides for infrastructure work
- The **human expertise** still required for core algorithm design
- The value of **collaboration** across different skillsets

Sometimes, the best engineering stories aren't about perfect toolsâ€”they're about the pivots you make when tools fall short, and the AI assistance that makes those pivots economically viable.

---

**Built with**: Python, Selenium, Flask, Cloudflare Workers, Railway, Claude Code
**GitHub**: [createsomethingtoday/zoom-transcript-extractor](https://github.com/createsomethingtoday/zoom-transcript-extractor)
**Contributors**: Huzaifa Tofeeq (Core Selenium Logic), Micah Johnson (Cloudflare Migration & Claude Code Integration)
